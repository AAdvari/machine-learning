{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning's \"Hello World\"!\n",
    "\n",
    "This is the assignment **#2** related to **Machine Learning** section of the **Artificial Intelligence** course at **Shahid Beheshti University**. ([Course repository link](https://github.com/SBU-CE/Artificial-Intelligence)).\n",
    "\n",
    "In this notebook, we explore the basic and traditional machine learning algorithms and see how to implement predictive models powered by [Sickit-Learn](https://scikit-learn.org/stable/) library.\n",
    "\n",
    " \n",
    " **Before you start:** Please read the ***Submission*** section at the bottom of the notebook carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets import the essential packages as usual\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Medical Insurance Cost Prediction\n",
    "\n",
    "Many factors that affect how much you pay for health insurance are not within your control. Nonetheless, it's good to have an understanding of what they are. Here are some factors that affect how much health insurance premiums cost:\n",
    "\n",
    "- **age**: age of primary beneficiary\n",
    "- **sex**: insurance contractor gender, female, male\n",
    "- **bmi**: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight using the ratio of height to weight, ideally 18.5 to 24.9\n",
    "- **smoker**: Smoking\n",
    "- **children**: Number of children covered by health insurance / Number of dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (1338, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>female</td>\n",
       "      <td>27.83</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>8515.7587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>male</td>\n",
       "      <td>32.70</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>34472.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>female</td>\n",
       "      <td>29.26</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>6184.2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>male</td>\n",
       "      <td>34.50</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>13822.8030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>female</td>\n",
       "      <td>24.10</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>2974.1260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     charges\n",
       "0   45  female  27.83         2     no   8515.7587\n",
       "1   24    male  32.70         0    yes  34472.8410\n",
       "2   34  female  29.26         3     no   6184.2994\n",
       "3   64    male  34.50         0     no  13822.8030\n",
       "4   27  female  24.10         0     no   2974.1260"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/insurance.csv')\n",
    "print(\"Shape of the dataset: {}\".format(df.shape))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a library named `pandas_profiling` in Python include a method named as `ProfileReport()` which generate a basic report on the input DataFrame. The report consist of the following:\n",
    "\n",
    "- DataFrame overview,\n",
    "- Each attribute on which DataFrame is defined,\n",
    "- Correlations between attributes (Pearson Correlation and Spearman Correlation), and\n",
    "- A sample of DataFrame.\n",
    "\n",
    "By running the cell below, a HTML file will be created next to the notebook in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77442b1963ee45c0a287ea29f0ea1be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83aa828463640d2ab2ad0cc03ca041d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347dda23ab7040f7be1eaf883527f04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d224d27f0048bf9eb969a28f8a1cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import pandas_profiling library\n",
    "import pandas_profiling as pp\n",
    "\n",
    "# forming ProfileReport and save\n",
    "# as a HTML file\n",
    "profile = pp.ProfileReport(df)\n",
    "profile.to_file(\"insurance_dataset_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Linear Regression\n",
    "\n",
    "**Linear Regression** is a machine learning algorithm based on **supervised learning**. It performs a regression task. Regression models a target prediction value based on independent variables. It is mostly used for finding out the relationship between variables and forecasting.\n",
    "<img src=\"images/linear-regression.png\" width=400 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we want to create a linear regression model for the existing dataest. For simplicity, we only consider one of the features of the data `bmi` and the target `charges`. Also we are just interested in the people who smokes. So:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'charges')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[df['smoker'] =='yes']['bmi'].values  # X now is a numpy array\n",
    "target = df[df['smoker'] =='yes']['charges'].values  # also target is a numpy array\n",
    "\n",
    "# plot the points\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(x = X, y = target)\n",
    "plt.xlabel(\"bmi\")\n",
    "plt.ylabel(\"charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Implement `SimpleLinearRegression` class. (20 points)\n",
    "\n",
    "Fill the blank lines with the least possible codes. Note that redundant codes may lead to reduce your score.\n",
    "\n",
    "**Note**: Do not add any other functions to the class defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class SimpleLinearRegression():\n",
    "    def __init__(self):\n",
    "        self.intercept = 0.0\n",
    "        self.coeff = 0.0\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        # TODO: Thin function takes X_train: numpy.ndarray and y : numpy.ndarray\n",
    "        # and fit a linear line to the points with the least loss\n",
    "        # Use sklearn.linear_model.LinearRegression for this purpose\n",
    "        # At last this function must set the intercept and coefficient of the predicted line\n",
    "        \n",
    "        intercept = 0.0\n",
    "        coeff = 0.0\n",
    "        ############# Your code here ############\n",
    "            \n",
    "        #########################################\n",
    "        \n",
    "        self.intercept = intercept\n",
    "        self.coeff = coeff\n",
    "        \n",
    "        return coeff, intercept\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true, loss_fn = 'MSE'):\n",
    "        # TODO: Implement this function that takes y_pred and y_true\n",
    "        # as a 1-dimensional numpy array (n_samples,) and returns\n",
    "        # the loss using sklearn.metrics functions\n",
    "         \n",
    "        possible_loss_functions = ['MSE', 'MAE', 'R2_Score']\n",
    "        \n",
    "        loss = None\n",
    "        if loss_fn == 'MSE':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        elif loss_fn == 'MAE':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        elif loss_fn == 'R2_Score':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        else:\n",
    "            error_str = 'Loss function is either unknown or not implemented.'\n",
    "            raise NotImplementedError(error_str)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def normalize(X, normalization='Standardization'):\n",
    "        # TODO: Implement this function that takes X : numpy.ndarray\n",
    "        # as the input feature array and normalize it\n",
    "        # You can use sklearn.preprocessing normalizations functions too.\n",
    "        # NOTE: For test set, you must use the mean and std of train set (standardization)\n",
    "        # of the train set. (since test set has not seen so far)\n",
    "        possible_normalization = ['Standardization', 'MinMaxScaling']\n",
    "        \n",
    "        nomalaized_feat = None\n",
    "        if normalization == 'Standardization':\n",
    "            ############# Your code here ############\n",
    "            nomalaized_feat = None\n",
    "            #########################################\n",
    "        elif normalization == 'MinMaxScaling':\n",
    "            ############# Your code here ############\n",
    "            nomalaized_feat = None\n",
    "            #########################################\n",
    "        else:\n",
    "            error_str = 'Normalization type is either unknown or not implemented.'\n",
    "            raise NotImplementedError(error_str)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def prepare_dataset(self, X, y, test_size=0.2, random_state=42):   \n",
    "        # TODO: Implement this function that takes X : numpy.ndarray and y : numpy.ndarray\n",
    "        # and use sklearn.model_selection.train_test_split to split your data into test and train sets\n",
    "        X_train, y_train, X_test, y_test = None, None, None, None\n",
    "        ############# Your code here ############\n",
    "    \n",
    "        #########################################\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. What are the coefficient and intercept of the trained linear model? (5 points)\n",
    "\n",
    "After completing the functions above, use them to report the final coefficient and intercept of the predicted model.\n",
    "\n",
    "**Note**: When implementing the `SimpleLinearRegression` class, notice that before training your model, normalize your input features for better convergence by completeing `normalize()` function. If you forget it, it may hurts your model consequently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr = SimpleLinearRegression()\n",
    "############# Your code here ############\n",
    "            \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Plot the prediceted line and the data points. (5 points)\n",
    "\n",
    "- Use `plt.scatter` to indicate the data points (Blue points for Train set and Red points for Test set).\n",
    "- Plot the predicted line using the coefficient and intercept calculated in the previous question. (`plt.plot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "            \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Compute loss. (5 points)\n",
    "\n",
    "First you must search about the following loss functions and compare them. (By showing their benefits to each other).\n",
    "\n",
    "- **MSE**: Mean Squared Error\n",
    "- **MAE**: Mean Absolute Error\n",
    "- **R2-score**\n",
    "\n",
    "Then create a DataFrame similar to the table shown below:\n",
    "\n",
    "| loss_function | train_set | test_set | \n",
    "| --- | --- | --- |\n",
    "| MSE | ... | ... |\n",
    "| MAE | ... | ... |\n",
    "| R2-score | ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "            \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Underfitting & Overfitting Issues\n",
    "\n",
    "A model is said to be a good machine learning model if it generalizes any new input data from the problem domain in a proper way. This helps us to make predictions in the future data, that the data model has never seen. Now, suppose we want to check how well our machine learning model learns and generalizes to the new data (Test set). For that, we have overfitting and underfitting, which are majorly responsible for the poor performances of the machine learning algorithms.\n",
    "\n",
    "- **Underfitting:** A statistical model or a machine learning algorithm is said to have underfitting when it cannot capture the underlying trend of the data. (It’s just like trying to fit undersized pants!) Underfitting destroys the accuracy of our machine learning model. Its occurrence simply means that our model or the algorithm **does not fit the data well enough**. It usually happens when we have fewer data to build an accurate model and also when we try to build a linear model with fewer non-linear data. In such cases, the rules of the machine learning model are too easy and flexible to be applied on such minimal data and therefore the model will probably make a lot of wrong predictions. Underfitting can be avoided by using more data and also reducing the features by feature selection. \n",
    "\n",
    "    Techniques to reduce underfitting: \n",
    "\n",
    "    1. Increase model complexity\n",
    "    2. Increase the number of features, performing feature engineering\n",
    "    3. Remove noise from the data.\n",
    "    4. Increase the number of epochs or increase the duration of training to get better results.\n",
    "    \n",
    "    \n",
    "- **Overfitting:** A statistical model is said to be overfitted when we train it with a lot of data (just like fitting ourselves in oversized pants!). When a model gets trained with so much data, it starts learning from the noise and inaccurate data entries in our data set. Then the model does not categorize the data correctly, because of too many details and noise. The causes of overfitting are the non-parametric and non-linear methods because these types of machine learning algorithms have more freedom in building the model based on the dataset and therefore they can really build unrealistic models. \n",
    "\n",
    "    Techniques to reduce overfitting: \n",
    "\n",
    "    1. Increase training data.\n",
    "    2. Reduce model complexity.\n",
    "    3. Early stopping during the training phase (have an eye over the loss over the training period as soon as loss begins to increase stop training).\n",
    "    4. Ridge Regularization and Lasso Regularization\n",
    "    \n",
    "    In the image below you can see linear regression and polynomial regression models. In the linear model, the model has underfitted and thus it cannot be generalized on all the data point properly (Underfitting). So we can add polynomial features as well to increase the complexity of the model. Therefore, in the middle figure you can see better fittnes of the model on the data points by adding $\\{x^2, x^3, x^4\\}$ to our hypothesis space.\n",
    "Although in the right side figure you see less loss than others, but the model is overfitted. It cannot be generalized on the test set (unseen data). \n",
    "    \n",
    "<img src=\"images/underfitting_overfitting.png\" width=700 height=700 />\n",
    "\n",
    "\n",
    "**Note:** The image above is not related to the given `insurance.csv` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. Implement `PolynomialRegression` class. (15 points)\n",
    "\n",
    "Fill the blank lines with using the least possible codes. Note that redundant codes may lead to reduce your score.\n",
    "\n",
    "**Note**: Do not add any other functions to the class defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class PolynomialRegression():\n",
    "    def __init__(self, degree=3):\n",
    "        self.degree = degree\n",
    "    \n",
    "    def train(self, X_train, y_train):\n",
    "        # TODO: Thin function takes X_train: numpy.ndarray and y : numpy.ndarray\n",
    "        # and fit a linear line to the points with the least loss\n",
    "        # Use sklearn.linear_model.LinearRegression for this purpose\n",
    "        # At last this function must set the intercept and coefficient of the predicted line\n",
    "        \n",
    "        intercept = None\n",
    "        coeff = None\n",
    "        ############# Your code here ############\n",
    "            \n",
    "        #########################################\n",
    "        \n",
    "        return coeff, intercept\n",
    "    \n",
    "    def compute_loss(self, y_pred, y_true, loss_fn = 'MSE'):\n",
    "        # TODO: Implement this function that takes y_pred and y_true\n",
    "        # as a 1-dimensional numpy array (n_samples,) and returns\n",
    "        # the loss using sklearn.metrics functions\n",
    "         \n",
    "        possible_loss_functions = ['MSE', 'MAE', 'R2_Score']\n",
    "        \n",
    "        loss = None\n",
    "        if loss_fn == 'MSE':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        elif loss_fn == 'MAE':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        elif loss_fn == 'R2_Score':\n",
    "            ############# Your code here ############\n",
    "            loss = 0.0\n",
    "            #########################################\n",
    "        else:\n",
    "            error_str = 'Loss function is either unknown or not implemented.'\n",
    "            raise NotImplementedError(error_str)\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def normalize(X, normalization='Standardization'):\n",
    "        # TODO: Implement this function that takes X : numpy.ndarray\n",
    "        # as the input feature array and normalize it\n",
    "        # You can use sklearn.preprocessing normalizations functions too.\n",
    "        # NOTE: For test set, you must use the mean and std of train set (standardization)\n",
    "        # of the train set. (since test set has not seen so far)\n",
    "        possible_normalization = ['Standardization', 'MinMaxScaling']\n",
    "        \n",
    "        nomalaized_feat = None\n",
    "        if normalization == 'Standardization':\n",
    "            ############# Your code here ############\n",
    "            nomalaized_feat = None\n",
    "            #########################################\n",
    "        elif normalization == 'MinMaxScaling':\n",
    "            ############# Your code here ############\n",
    "            nomalaized_feat = None\n",
    "            #########################################\n",
    "        else:\n",
    "            error_str = 'Normalization type is either unknown or not implemented.'\n",
    "            raise NotImplementedError(error_str)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def generate_polynomial_features(self, X, degree):\n",
    "        # TODO: Implement this function that takes degree: int and X: numpy.ndarray\n",
    "        # to return polnomial features of those input features.\n",
    "        # Use sklearn.preprocessing.PolynomialFeatures. Read its documentation for more info.\n",
    "        X_pol = None\n",
    "        ############# Your code here ############\n",
    "    \n",
    "        #########################################\n",
    "        \n",
    "        return X_pol\n",
    "        \n",
    "\n",
    "    def prepare_dataset(self, X, y, test_size=0.2, random_state=42):   \n",
    "        # TODO: Implement this function that takes X : numpy.ndarray and y : numpy.ndarray\n",
    "        # and use sklearn.model_selection.train_test_split to split your data into test and train sets\n",
    "        X_train, y_train, X_test, y_test = None, None, None, None\n",
    "        ############# Your code here ############\n",
    "    \n",
    "        #########################################\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6. Find the best polynomial degree. (10 points)\n",
    "\n",
    "The best polynomial degree is the one with the least loss for test set data points. So use the implemented `PolynomialRegression`above multiple times to find the best one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(20):\n",
    "    best_degree = 1\n",
    "    least_loss = 0.0\n",
    "    pr = PolynomialRegression(degree=degree)\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7. Plot some experimental results (5 points)\n",
    "\n",
    "Use `plt.subplot` to plot the predicted polynomial model **for degrees, 1, 4 and 20**.\n",
    "\n",
    "So note that you must present 1 figure with 3 plots.\n",
    "\n",
    "Also consider these:\n",
    "- Set the title of each plot to ***Polynomial Fit degree i***\n",
    "- Print loss of each model on both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "    \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Mall Customer Clustering\n",
    "\n",
    "How to customize our services for an existing mall customers? One way to do this is to cluster customers based on some information(features) we have from them. Customers with similar features must be corresponded to the samed clusters(groups).\n",
    "\n",
    "There is a dataset `datasets/mall_customers.csv` which can be found in the project directory. It has the following features per example:\n",
    "\n",
    "- **sex**: customer gender, female, male\n",
    "- **age**: customer age\n",
    "- **annual_income**: estimated annual income of each customer (k\\$)\n",
    "- **spending_score**: An interger value between 0 and 100 which indicates the score of the customer for his/her ability for purchasing products.\n",
    "\n",
    "In this problem we are going to cluster the customers based on their `annual_income` and `spending_score` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (200, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>spending_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>31</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex  age  annual_income  spending_score\n",
       "0    Male   19             15              39\n",
       "1    Male   21             15              81\n",
       "2  Female   20             16               6\n",
       "3  Female   23             16              77\n",
       "4  Female   31             17              40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/mall_customers.csv')\n",
    "print(\"Shape of the dataset: {}\".format(df.shape))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'spending_score')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df[['annual_income', 'spending_score']]\n",
    "\n",
    "# plot the points\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.scatter(X['annual_income'], X['spending_score'])\n",
    "plt.xlabel(\"annual_income\")\n",
    "plt.ylabel(\"spending_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 K-means clustering algorithm\n",
    "\n",
    "We are given a data set of items, with certain features, and values for these features (like a vector). The task is to categorize those items into groups. To achieve this, we will use the kMeans algorithm; an **unsupervised** learning algorithm. \n",
    "\n",
    "The algorithm will categorize the items into k groups of similarity. To calculate that similarity, we will use the euclidean distance as measurement.\n",
    "\n",
    "The algorithm works as follows:\n",
    "\n",
    "1. First, we initialize $k$ points, called means(centroids), randomly.\n",
    "2. We categorize each item to its closest mean and we update the mean’s coordinates, which are the averages of the items categorized in that mean so far.\n",
    "3. We repeat the process for a given number of iterations and at the end, we have our clusters.\n",
    "\n",
    "The *points* mentioned above are called means because they hold the mean values of the items categorized in them. To initialize these means, we have a lot of options. An intuitive method is to initialize the means at random items in the data set.\n",
    "\n",
    "The above algorithm in pseudocode: \n",
    "\n",
    "```\n",
    "Initialize k means with random values\n",
    "\n",
    "For a given number of iterations:\n",
    "    Iterate through items:\n",
    "        Find the mean closest to the item\n",
    "        Assign item to mean\n",
    "        Update mean\n",
    "```\n",
    "\n",
    "Hopefully in this assignment we will not implement this algorithm from scratch. Sickit-learn library has provided it for us and we will use it readily.\n",
    "\n",
    "<img src=\"images/kmeans.png\" width=700 height=700 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8. Train a Kmeans model (15 points)\n",
    "\n",
    "You must use `sklearn.cluster.KMeans` functionalities to implement a kmeans. Follow the steps below:\n",
    "\n",
    "1. Initiallize the kmeans model with $k=5$\n",
    "2. Fit the model on the training set.\n",
    "3. Assign the learnt clusters to testing set points\n",
    "4. Compute WCSS criteria for the trained model(kmeans.inertia_)\n",
    "\n",
    "\n",
    "Note: You may need to read the documentation of the scikit learn library for kmeans entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# split data to train and test sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.1, random_state=42)\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9. Plot the clusters and their centroids. (15 points)\n",
    "\n",
    "Plot the data points and their clusters centroids with different colors (You must use 5 colors, one per cluster).\n",
    "\n",
    "Use as much as matplotlib functionalities for more interesting plots.\n",
    "\n",
    "**Note that the more understandable and exciting your figures are, the more score you will get!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Your code here ############\n",
    "    \n",
    "#########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10. Elbow diagram (10 points)\n",
    "\n",
    "**Which value for $k$?!** \n",
    "\n",
    "Search about Elbow diagram for kmeans. Write about it here briefly and plot the Elbow diagram to achieve the best paramater $k$ for our kmeans algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    best_k = 1\n",
    "    loss = []\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Submission\n",
    "\n",
    "Please read the notes here carefully:\n",
    "\n",
    "1. The more beautiful and insightfull your plots and diagrams are, the more points you get. So please take your time and concentration to prepare a good report with nice diagrams.\n",
    "\n",
    "2. Copy and paste all the codes you have implemented in a `Utils.py` file. Note that you won't need to add any other functions and you just have to copy and paste the functions which have ***\\\"Your code here\\\"*** comments in its body.\n",
    "\n",
    "3. The file you upload must be named as `[Student ID]-[Your name].zip` and it must contain **only 2 files**:\n",
    "\n",
    "  - `BasicMachineLearningAlgorithms.ipynb`\n",
    "  - `Utils.py`\n",
    "  \n",
    "4. **Important Note**: The outputs of the code blocks must be remained in your notebook, otherwise, you definitly lose all the points of that \n",
    "  \n",
    "In case you have any questions, contact **mohammad99hashemi@gmail.com**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
